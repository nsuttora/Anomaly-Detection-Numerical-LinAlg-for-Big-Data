{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 1841\n",
      "Number of validation files: 399\n",
      "Number of test files: 867\n",
      "\n",
      "Number of tumor images in test set: 129\n",
      "Number of non-tumor images in test set: 738\n"
     ]
    }
   ],
   "source": [
    "# using Arnold's method of loading data\n",
    "train_path =  'MRIscans/Training/'\n",
    "val_path = 'MRIscans/Validation/'\n",
    "test_path = 'MRIscans/Testing/'\n",
    "\n",
    "train_files = glob.glob(os.path.join(train_path, 'no_tumor_train', '*.*'))\n",
    "val_files = glob.glob(os.path.join(val_path, 'no_tumor_val', '*.*'))\n",
    "\n",
    "test_files_pos = glob.glob(os.path.join(test_path, 'tumor_test', '*.*'))\n",
    "test_files_neg = glob.glob(os.path.join(test_path, 'no_tumor', '*.*'))\n",
    "test_files = test_files_pos + test_files_neg\n",
    "\n",
    "test_labels = np.array([0]*len(test_files_pos)+[1]*len(test_files_neg))\n",
    "\n",
    "print(f'Number of training files: {len(train_files)}')\n",
    "print(f'Number of validation files: {len(val_files)}')\n",
    "print(f'Number of test files: {len(test_files)}')\n",
    "\n",
    "print(f'\\nNumber of tumor images in test set: {len(test_files_pos)}')\n",
    "print(f'Number of non-tumor images in test set: {len(test_files_neg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRIscans/Training/no_tumor_train\\1 no.jpeg\n",
      "MRIscans/Validation/no_tumor_val\\Tr-no_0825.jpg\n",
      "MRIscans/Testing/tumor_test\\p (179).jpg\n"
     ]
    }
   ],
   "source": [
    "print(train_files[0])\n",
    "print(val_files[0])\n",
    "print(test_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_prep_imgs(files):\n",
    "    # load the images from the path with size 250x250\n",
    "    imgs = [load_img(img_path, target_size=(250, 250)) for img_path in files]\n",
    "    # convert list of images to numpy array\n",
    "    dataset = np.array([img_to_array(img) for img in imgs])\n",
    "    # appropriately preprocess images for resnet use\n",
    "    dataset = preprocess_input(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:     (1841, 250, 250, 3)\n",
      "Validation Set:   (399, 250, 250, 3)\n",
      "Testing Set:      (867, 250, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = read_and_prep_imgs(train_files)\n",
    "val_dataset = read_and_prep_imgs(val_files)\n",
    "test_dataset = read_and_prep_imgs(test_files)\n",
    "\n",
    "print('Training Set:    ', train_dataset.shape)\n",
    "print('Validation Set:  ', val_dataset.shape)\n",
    "print('Testing Set:     ', test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Class SVM & Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASIC IDEA\\\n",
    "first apply a pre-trained CNN to extract a meaningful compact representation of the images\\\n",
    "use those vectors as input to a one-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction with ResNet50\n",
    "# Removing the prediction layer of the pretrained Resnet50 model allows features to quickly be extracted from selected images.\n",
    "\n",
    "# don't include top since that FC layer is used for predictions\n",
    "resnet_model = ResNet50(input_shape=(250,250,3), weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "train_features = resnet_model.predict(train_dataset)\n",
    "#val_features = resnet_model.predict(val_dataset)\n",
    "#test_features = resnet_model.predict(test_dataset)\n",
    "# TODO: haven't fully ran yet, taking over 10mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run after above solved\n",
    "oneclass_svm = svm.OneClassSVM(kernel='rbf')\n",
    "iso_forest = IsolationForest(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "oneclass_svm.fit(train_dataset)\n",
    "iso_forest.fit(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a707a455a0e3f992522d00abd4d915e89875d212a94269518ed4ba304f0c759f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
